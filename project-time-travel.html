<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Time-Aware EDA & Leakage Detection – Yiying Huang</title>
  <meta name="description" content="Leakage audit, temporal cross-validation, and past-only feature engineering for realistic model evaluation." />
  <link rel="stylesheet" href="assets/style.css" />
</head>
<body>
  <header class="site-header">
    <a class="brand" href="index.html">YIYING HUANG</a>
    <nav class="nav">
      <a href="index.html">Home</a>
      <a class="active" href="projects.html">Projects</a>
      <a href="about.html">About</a>
      <a href="contact.html">Contact</a>
    </nav>
  </header>

  <main class="container">
    <p class="small"><a class="text-link" href="projects.html">← Back to Projects</a></p>
    <h1>Time-Aware EDA & Leakage Detection</h1>
    <p class="muted small">Event-time classification case study</p>

    <p>
      This project demonstrates how to detect and prevent “time-travel” (target) leakage in event-time data.
      The pipeline includes a systematic leakage audit, purged temporal cross-validation, past-only feature engineering,
      and fair benchmarking to obtain trustworthy out-of-sample estimates.
    </p>

    <!-- 1) Problem & Data -->
    <section class="project" id="overview">
      <h2>Problem & Data</h2>
      <p>
        We work with time-stamped user events and labels. A naive random split overestimates performance because records from the
        same user/time neighborhood can leak future information into training. The goal is an evaluation protocol that
        mimics real-time deployment.
      </p>

      <figure class="card">
        <img src="assets/projects/date_y Year 1.png" alt="Label distribution over time (Year 1)" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Year 1 overview of label/time coverage</figcaption>
      </figure>
      <figure class="card">
        <img src="assets/projects/date_y Year 2.png" alt="Label distribution over time (Year 2)" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Year 2 overview of label/time coverage</figcaption>
      </figure>
      <figure class="card">
        <img src="assets/projects/date_y Year 3.png" alt="Label distribution over time (Year 3)" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Year 3 overview of label/time coverage</figcaption>
      </figure>
    </section>

    <!-- 2) Leakage Audit -->
    <section class="project" id="leakage">
      <h2>Leakage Audit</h2>
      <p>
        We compare temporal distributions between train and test and inspect class probability drift over time.
        Mismatches or sharp drifts signal potential target leakage or improper splits.
      </p>

      <figure class="card">
        <img src="assets/projects/date x distribution train vs test.png" alt="date_x distribution: train vs test" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Feature-time (<code>date_x</code>) distribution — train vs. test</figcaption>
      </figure>

      <figure class="card">
        <img src="assets/projects/date_y distribution (first year) train vs test.png" alt="date_y distribution first year: train vs test" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Label-time (<code>date_y</code>) distribution — train vs. test (first year)</figcaption>
      </figure>

      <figure class="card">
        <img src="assets/projects/date_y distribution (last year) train vs test.png" alt="date_y distribution last year: train vs test" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Label-time (<code>date_y</code>) distribution — train vs. test (last year)</figcaption>
      </figure>

      <figure class="card">
        <img src="assets/projects/date_x class prob &amp; frequency.png" alt="Class probability and frequency over date_x" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Class probability &amp; frequency over <code>date_x</code> (time-varying target check)</figcaption>
      </figure>
    </section>

    <!-- 3) Temporal CV Design -->
    <section class="project" id="cv">
      <h2>Temporal Cross-Validation</h2>
      <p>
        We replace random K-Fold with a <strong>rolling-origin split</strong> and a <strong>purged, embargoed GroupKFold</strong>
        (grouped by user/session). Purging removes samples within an embargo window around fold boundaries to avoid look-ahead bias.
        This aligns CV with real deployment where only the past is available at decision time.
      </p>

      <figure class="card">
        <img src="assets/projects/temporal_cv.png" alt="Temporal cross-validation scheme: rolling origin with purged, embargoed GroupKFold" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Temporal CV scheme: rolling origin + group-aware purging/embargo</figcaption>
      </figure>
    </section>

    <!-- 4) Past-Only Feature Engineering -->
    <section class="project" id="features">
      <h2>Past-Only Feature Engineering</h2>
      <p>
        Features are rebuilt using only information available up to the event time: lagged aggregates, rolling windows, and
        count/frequency encodings per user or entity. Any post-event fields are dropped or shifted so that training and inference
        share the same information set.
      </p>

      <figure class="card">
        <img src="assets/projects/past_only_features.png" alt="Past-only feature construction with lagged and rolling statistics" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Past-only feature construction (lagged & rolling statistics)</figcaption>
      </figure>
    </section>

    <!-- 5) Benchmarks & Results -->
    <section class="project" id="results">
      <h2>Benchmarks &amp; Results</h2>
      <ul>
        <li><strong>Naive random split:</strong> optimistic metrics due to leakage.</li>
        <li><strong>Temporal CV (purged):</strong> lower but realistic CV; hold-out aligns with CV, indicating reliable generalization.</li>
      </ul>

      <figure class="card">
        <img src="assets/projects/benchmarks_results.png" alt="Benchmark results comparing random split vs temporal CV and hold-out" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Random split vs. temporal CV & hold-out: realistic performance after leakage control</figcaption>
      </figure>
    </section>

    <!-- 6) Lessons Learned -->
    <section class="project" id="takeaways">
      <h2>Lessons Learned</h2>
      <ul>
        <li>Always audit for time-travel leakage before modeling; enforce past-only features.</li>
        <li>Use temporal, group-aware CV with purging/embargo for event-time problems.</li>
        <li>Report both CV and time-aligned hold-out; avoid random splits.</li>
      </ul>

      <figure class="card">
        <img src="assets/projects/lessons_learned.png" alt="Key practices and lessons learned" style="width:100%;border-radius:12px" />
        <figcaption class="meta">Key practices to make time-aware modeling trustworthy</figcaption>
      </figure>
    </section>

    <p class="meta" style="margin-top:12px">
      Tech Stack: Python · pandas · numpy · scikit-learn
    </p>

    <p class="small"><a class="text-link" href="projects.html">← Back to Projects</a></p>
  </main>

  <footer class="site-footer">
    © <span id="year"></span> Yiying Huang · <a href="https://github.com/huangyiying331">GitHub</a>
  </footer>
  <script>document.getElementById('year').textContent = new Date().getFullYear();</script>
</body>
</html>
